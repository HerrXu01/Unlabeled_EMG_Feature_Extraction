{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**  \n",
    "chatemg源代码输入数据是整型，注意数据类型  \n",
    "记得在Dataset的实现中加入针对chatemg对数据加偏移量的操作，确保数据中没有负数  \n",
    "记得转换形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_yaml(\"configs/senic/transformer.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': {'name': 'SeNic', 'src': 'datasets/raw/senic_s0', 'sampling_frequency': 200, 'num_channels': 8}, 'data_preprocess': {'enable_filter': False, 'enable_window': True, 'enable_save_windows': False}, 'window': {'type': 'fixed_step', 'window_size': 50, 'step_size': 10, 'windows_dir': 'datasets/windows/senic_s0', 'filename': 'win50_step10.npy'}, 'model': {'name': 'Transformer4EMG', 'N_embed': 256, 'num_attention_heads': 16, 'num_encoder_layers': 4, 'dropout_prob': 0.2, 'enable_norm': True, 'channels_weight_share': False}, 'train': {'val_size': 0.2, 'batch_size': 32, 'enable_shuffle': True, 'criterion': 'Huber', 'num_epochs': 50, 'optimizer': 'AdamW', 'weight_decay': 0.01, 'learning_rate': 0.0001, 'save_checkpoint': False, 'best_model_path': 'checkpoints/senic/win50_stp10/transformer/Nembed128_atthead8_encodelay2.pth', 'enable_lr_decay': True, 'lr_decay_step': 10, 'lr_decay_gamma': 0.5}, 'wandb': {'enable_wandb': True, 'sweep_count': 30, 'project': 'Unlabeled_EMG_Feature_Extraction', 'name': 'SeNic_win50_stp10_transformer_sweep'}}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\potnet\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\anaconda\\envs\\potnet\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from trainer.base_trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full windows data is of the shape (361610, 50, 8).\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = trainer.load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-128.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(108.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 49, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.chatemg import ChatEMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"dataset\": {\"num_channels\": 8},\n",
    "    \"window\": {\"window_size\": 51},\n",
    "    \"model\": {\"vocab_size\": 256, \"n_embed\": 256, \"n_layer\": 12, \"bias\": False, \"dropout\": 0.2, \"n_head\": 8, \"token_embedding_type\": \"basic_sum\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "number of parameters: 19.61M\n"
     ]
    }
   ],
   "source": [
    "model  = ChatEMG(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs + 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5892e-01,  7.0319e-02, -2.6995e-01,  ..., -1.0934e-01,\n",
       "           8.3383e-02, -6.0019e-02],\n",
       "         [ 7.3120e-03,  9.5174e-02, -5.1272e-02,  ..., -2.2744e-01,\n",
       "           1.7741e-01,  1.5233e-01],\n",
       "         [-8.3877e-02,  2.0542e-01, -2.6533e-02,  ...,  1.2038e-01,\n",
       "           4.4543e-03, -1.1511e-02],\n",
       "         ...,\n",
       "         [-7.8506e-02,  2.1880e-01, -1.0634e-01,  ..., -4.4795e-02,\n",
       "           2.0684e-01,  1.3831e-01],\n",
       "         [-8.4222e-02,  1.0154e-01, -1.3176e-01,  ..., -3.5816e-02,\n",
       "           2.0851e-01, -1.2649e-01],\n",
       "         [ 1.1979e-01, -1.1941e-01,  3.5390e-02,  ..., -9.8970e-02,\n",
       "           2.4595e-01,  1.8922e-02]],\n",
       "\n",
       "        [[ 2.9107e-02, -8.2068e-02, -1.3767e-01,  ..., -7.1803e-02,\n",
       "           3.2093e-01, -3.8027e-02],\n",
       "         [ 1.3213e-01, -1.8866e-01,  7.5148e-02,  ..., -1.3158e-01,\n",
       "           3.1331e-02,  9.2463e-02],\n",
       "         [ 2.1166e-01, -2.6367e-01, -2.2436e-01,  ..., -1.5369e-01,\n",
       "           9.7096e-02,  1.8860e-01],\n",
       "         ...,\n",
       "         [-1.7371e-02, -2.5812e-01, -6.5616e-02,  ..., -1.3960e-01,\n",
       "           7.6807e-02,  1.0265e-01],\n",
       "         [ 1.6150e-01, -2.9141e-01, -6.8315e-02,  ..., -1.7865e-01,\n",
       "           1.3095e-01,  4.9623e-02],\n",
       "         [ 1.3216e-01, -2.2094e-01, -1.1628e-01,  ...,  9.1160e-03,\n",
       "           1.3166e-01,  1.1075e-01]],\n",
       "\n",
       "        [[-2.9756e-02, -4.9992e-02,  1.0419e-01,  ...,  9.5657e-02,\n",
       "           2.8181e-02, -4.8675e-02],\n",
       "         [ 8.1489e-02, -9.9205e-02,  3.8016e-02,  ...,  2.0721e-01,\n",
       "           1.5372e-01,  1.2069e-02],\n",
       "         [ 1.6319e-01, -3.5318e-02, -3.5563e-04,  ...,  1.3832e-01,\n",
       "           1.1744e-01, -9.4169e-02],\n",
       "         ...,\n",
       "         [ 2.3165e-01, -1.1692e-01, -7.3417e-02,  ...,  3.2139e-01,\n",
       "           6.9944e-02, -1.5734e-01],\n",
       "         [ 1.4886e-01,  6.9987e-02,  1.7618e-01,  ...,  9.9442e-02,\n",
       "           7.0606e-02,  1.1424e-01],\n",
       "         [-1.0310e-01,  3.7721e-02, -1.4373e-02,  ...,  2.2107e-01,\n",
       "           3.6186e-02, -1.7426e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-6.4670e-02,  1.9575e-01,  4.9078e-03,  ..., -3.5771e-02,\n",
       "           3.6151e-02, -2.4049e-02],\n",
       "         [-1.0191e-02,  4.3374e-02,  9.1786e-02,  ..., -2.2105e-01,\n",
       "          -7.3466e-02,  1.5891e-02],\n",
       "         [ 9.7685e-02,  6.8275e-02, -1.5826e-01,  ..., -6.8428e-02,\n",
       "           2.4504e-01, -7.5601e-03],\n",
       "         ...,\n",
       "         [-1.1289e-01,  1.1165e-02, -2.0955e-02,  ..., -9.6887e-02,\n",
       "           1.3515e-01,  6.8707e-02],\n",
       "         [-1.5368e-01,  1.7044e-01, -1.7853e-02,  ..., -1.9921e-01,\n",
       "           1.7762e-03, -1.9524e-01],\n",
       "         [ 1.1971e-01,  7.2605e-02,  1.7260e-02,  ..., -1.0500e-01,\n",
       "           1.5789e-02, -1.5900e-01]],\n",
       "\n",
       "        [[-6.1360e-02,  1.4372e-02, -3.3367e-02,  ...,  1.2808e-01,\n",
       "           2.1920e-01,  1.2315e-01],\n",
       "         [ 2.9302e-02, -3.6991e-02,  1.1304e-03,  ...,  7.2365e-02,\n",
       "           1.6430e-01,  6.0265e-02],\n",
       "         [ 2.3875e-02,  1.2448e-02,  1.5919e-01,  ..., -1.6033e-02,\n",
       "           1.7261e-01,  1.8223e-01],\n",
       "         ...,\n",
       "         [-1.0203e-01,  5.7479e-03, -7.6884e-02,  ..., -5.4686e-02,\n",
       "           8.4642e-02,  1.2451e-02],\n",
       "         [-1.7909e-01, -3.7617e-02, -4.3409e-02,  ..., -1.3257e-01,\n",
       "           2.0376e-01,  2.8257e-01],\n",
       "         [-5.5602e-02, -2.2385e-01, -9.0021e-02,  ..., -1.9239e-01,\n",
       "           1.1860e-01,  5.1745e-02]],\n",
       "\n",
       "        [[-2.4548e-01,  4.0272e-02,  1.7676e-01,  ..., -6.6123e-02,\n",
       "           5.6377e-02, -2.1902e-01],\n",
       "         [-2.8326e-02, -8.7621e-03,  5.4722e-02,  ..., -4.8749e-02,\n",
       "           1.9120e-01, -9.8151e-02],\n",
       "         [-2.9496e-01,  6.4943e-02,  7.0425e-02,  ..., -1.1625e-01,\n",
       "           4.5804e-03, -1.8072e-01],\n",
       "         ...,\n",
       "         [-3.6243e-01,  3.6784e-02,  1.4620e-01,  ...,  2.0358e-01,\n",
       "           2.2348e-01, -7.0548e-02],\n",
       "         [ 1.6637e-01,  1.0162e-01,  3.8002e-02,  ..., -1.7971e-01,\n",
       "           1.6162e-01, -2.0917e-02],\n",
       "         [-2.2517e-01,  1.8755e-01,  3.5189e-02,  ...,  2.2665e-02,\n",
       "          -6.1710e-02, -2.6126e-01]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 256])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(outputs + 1).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256 // 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = read_yaml(\"configs/chatemg/chatemg_senic.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(config1[\"dataset\"][\"offset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\potnet\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(a.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('potnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8c3876850c79236481b23140a76c58b380d03d2d84cfe85e0babb0d139ed46e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
